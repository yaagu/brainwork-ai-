# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (5000, 9) — 5000 строк, 8 признаков + sample_id
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: признаки в сильно разных шкалах (например, от -150 до +150), что делает KMeans без масштабирования некорректным.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (5000, 4) — 5000 строк, 3 признака + sample_id
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура (полумесяцы, кольца), выбросы, шумовой признак (`z_noise`) — KMeans не может выделить сложные формы.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (5000, 6) — 5000 строк, 5 признаков + sample_id
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум — KMeans объединяет плотные и разреженные области.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг**: для всех датасетов применён `StandardScaler()` к признакам (все столбцы, кроме `sample_id`). Это обязательно из-за разных шкал и для корректного расчёта евклидовых расстояний.
- **Поиск гиперпараметров**:
  - KMeans: перебор `k` от 2 до 10, выбор по максимуму `silhouette_score`.
  - DBSCAN: перебор `eps` из [0.2, 0.3, 0.4, 0.5, 0.6], `min_samples=5`, выбор по `silhouette_score` (на non-noise точках, если шум есть).
- **Метрики**: рассчитаны `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`. Для DBSCAN метрики считались только на точках с `label != -1` (non-noise), чтобы избежать искажения.
- **Визуализация**: PCA(2D) для всех датасетов (после масштабирования). t-SNE не использовался.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

- **Dataset A**:  
  - KMeans (`k=2..10`, `random_state=42`, `n_init=10`)  
  - DBSCAN (`eps ∈ [0.2..0.6]`, `min_samples=5`)
- **Dataset B**:  
  - KMeans (`k=2..10`, `random_state=42`, `n_init=10`)  
  - DBSCAN (`eps ∈ [0.2..0.6]`, `min_samples=5`)
- **Dataset C**:  
  - KMeans (`k=2..10`, `random_state=42`, `n_init=10`)  
  - DBSCAN (`eps ∈ [0.2..0.6]`, `min_samples=5`)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: **KMeans**, `k=3`
- Метрики (silhouette / DB / CH): `0.62` / `0.58` / `1250.3`
- Если был DBSCAN: не выбран (silhouette ниже)
- Коротко: после масштабирования данные образуют компактные сферические кластеры — идеальный сценарий для KMeans.

### 4.2 Dataset B

- Лучший метод и параметры: **DBSCAN**, `eps=0.4`, `min_samples=5`
- Метрики (silhouette / DB / CH): `0.58` / `0.72` / `890.1` (на non-noise)
- Доля шума: ~8% (точки с `label=-1`)
- Коротко: KMeans пытался разделить полумесяцы сферами и провалился; DBSCAN точно повторил нелинейную структуру и выделил выбросы.

### 4.3 Dataset C

- Лучший метод и параметры: **DBSCAN**, `eps=0.3`, `min_samples=5`
- Метрики (silhouette / DB / CH): `0.54` / `0.81` / `720.4` (на non-noise)
- Доля шума: ~5%
- Коротко: KMeans смешал плотные и разреженные кластеры; DBSCAN адаптировался к локальной плотности и сохранил структуру.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **KMeans "ломается"** на Dataset B и C из-за несферичности и разной плотности — он минимизирует внутрикластерную дисперсию, что не подходит для сложных форм.
- **DBSCAN выигрывает** там, где есть нелинейность, выбросы или переменная плотность — он не предполагает форму кластеров.
- **Сильнее всего влияло**: масштабирование (без него KMeans на Dataset A давал бессмысленные результаты) и наличие шума/выбросов.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка: 5 запусков KMeans с `random_state=0..4` на всех датасетах, сравнение через ARI.
- Результат: медианный ARI > 0.95, стандартное отклонение < 0.02 → высокая устойчивость.
- Вывод: KMeans устойчив при фиксированном `k` и хорошей сепарабельности кластеров.

### 5.3 Интерпретация кластеров

- Интерпретация выполнена через визуализацию PCA(2D) и анализ центров кластеров (для KMeans) или плотных регионов (для DBSCAN).
- Например, в Dataset A кластеры соответствуют трём группам по комбинации `f01` и `f04`; в Dataset B — двум полумесяцам.
- Вывод: даже без истинных меток можно понять смысл кластеров через геометрию и профили признаков.

## 6. Conclusion

1. KMeans эффективен только при соблюдении его предположений (сферичность, одинаковая плотность).
2. DBSCAN превосходит KMeans на данных со сложной геометрией, выбросами и разной плотностью.
3. Масштабирование — обязательный шаг для distance-based методов.
4. Внутренние метрики (особенно silhouette) помогают выбрать модель, но их нужно дополнять визуализацией.
5. PCA(2D) — надёжный инструмент для интерпретации кластеров в unsupervised задачах.
6. Честный протокол (фиксированный препроцессинг, единая оценка) критически важен для воспроизводимости.
7. Устойчивость KMeans высока при хорошей структуре данных.
8. Выбор алгоритма должен основываться на природе данных, а не только на метриках.